{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car model training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girijeshcse/car_finder/blob/nitya/notebooks/Car_model_training_1207.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckPVrt8k877-"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGofwFRMvBLn"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXXEdlZLvCGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a51c67-915c-41c7-9102-4cd2f068bc3f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XbLzOjIJiLJ"
      },
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/Capstone/Dataset_1/Dataset/'\n",
        "TRAIN_IMAGES_PATH = os.path.sep.join([BASE_PATH, \"Car Images/Train Images\"])\n",
        "TEST_IMAGES_PATH = os.path.sep.join([BASE_PATH, \"Car Images/Test Images\"])\n",
        "TRAIN_ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"Annotations/Train Annotations.csv\"])\n",
        "TEST_ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"Annotations/Test Annotations.csv\"])\n",
        "CAR_NAMES_MAKE_DICT = os.path.sep.join([BASE_PATH, \"Car names and make.csv\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgmN84eN-eYd"
      },
      "source": [
        "# load the contents of the CSV annotations file\n",
        "# initialize the list of data (images), our target output predictions\n",
        "# (bounding box coordinates), along with the filenames of the\n",
        "# individual images\n",
        "data = []\n",
        "targets = []\n",
        "trainfilenames = []\n",
        "testfilenames = []\n",
        "labels = []\n",
        "bboxes = []\n",
        "trainimagePaths = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQfWV9I4SEA-"
      },
      "source": [
        "import pandas as pd \n",
        "car_map = pd.read_csv(CAR_NAMES_MAKE_DICT,names=['Cars'])\n",
        "car_map = car_map.set_index('Cars')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_HAm_ikTkRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1d5019-f07d-4125-bf65-bb838a7ec40e"
      },
      "source": [
        "car_map_dict=car_map.to_dict('index')\n",
        "list(car_map_dict.items())[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AM General Hummer SUV 2000', {}),\n",
              " ('Acura RL Sedan 2012', {}),\n",
              " ('Acura TL Sedan 2012', {}),\n",
              " ('Acura TL Type-S 2008', {}),\n",
              " ('Acura TSX Sedan 2012', {})]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL8sWNBnWnaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3385ca-3c75-4b09-d0f0-b9b3c9f1b21e"
      },
      "source": [
        "#fetch a key based on value passed - we need this to build our image paths\n",
        "print(list(car_map_dict.keys())[173])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ram C/V Cargo Van Minivan 2012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVKm_OlMO7Ts"
      },
      "source": [
        "import csv\n",
        "with open(TRAIN_ANNOTS_PATH, newline='') as file:\n",
        "    \n",
        "    reader = csv.reader(file, delimiter = ' ')\n",
        "    \n",
        "    # store the headers in a separate variable,\n",
        "    # move the reader object to point on the next row\n",
        "    headings = next(reader)\n",
        "      \n",
        "    # output list to store all rows\n",
        "    Output = []\n",
        "    for row in reader:\n",
        "        Output.append(row[:])\n",
        "  \n",
        "for row in Output:\n",
        "    row = str(row)\n",
        "    row = row.split(\",\")\n",
        "    (filename, startX, startY, endX, endY, label) = row\n",
        "    filename = filename.split(\"'\",1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L2brBTI3_wg"
      },
      "source": [
        "dfRows=[]\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/Capstone/Dataset_1/Dataset/Car Images/Train Images'):\n",
        "  limit=0\n",
        "  if len(filenames) < 20 or 20 == 0:\n",
        "    limit=len(filenames)\n",
        "  else:\n",
        "    limit=20\n",
        "  for i in range(0,limit):\n",
        "    if not os.path.isfile(os.path.join('/content/drive/MyDrive/Capstone/Dataset_1/Dataset/Car Images/Train Images', filenames[i])):\n",
        "      processedRows=[]\n",
        "      filename=filenames[i]\n",
        "      processedRows.append(filename)\n",
        "      pathSplits=dirname.split('/')\n",
        "      #print(os.path.join(dirname, filename))\n",
        "      imagePathtrain=os.path.join(dirname, filename)\n",
        "      #print(imagePathtrain)\n",
        "      image = cv2.imread(imagePathtrain)\n",
        "      (h, w) = image.shape[:2]\n",
        "      # scale the bounding box coordinates relative to the spatial dimensions of the input image\n",
        "      startX = float(startX) / w\n",
        "      startY = float(startY) / h\n",
        "      endX = float(endX) / w\n",
        "      endY = float(endY) / h\n",
        "      # load the image and preprocess it\n",
        "      image = load_img(imagePathtrain, target_size=(224, 224))\n",
        "      image_array = img_to_array(image)\n",
        "      # update our list of data, targets, and filenames\n",
        "      data = np.append(data, image_array)\n",
        "      processedRows.append(data)\n",
        "      processedRows.append(labels)\n",
        "      bboxes = np.append(bboxes, (startX, startY, endX, endY))\n",
        "      processedRows.append(bboxes)\n",
        "      trainimagePaths = np.append(trainimagePaths,imagePathtrain)\n",
        "      processedRows.append(trainimagePaths)\n",
        "      dfRows.append(processedRows)\n",
        "      df=pd.DataFrame(dfRows, columns=[\"fileName\",\"image_array\",\"data\",\"bboxes\",\"trainimagePaths\"]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNIbbJ4G8YSA"
      },
      "source": [
        "df.to_csv('/content/drive/MyDrive/Capstone/Dataset_1/Imgarray.csv')           "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}