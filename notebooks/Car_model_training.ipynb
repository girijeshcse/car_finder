{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car model training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyN6VSXLlE7kGCZ2UEPwB85r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girijeshcse/car_finder/blob/sushweta/notebooks/Car_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0JlASgT886f"
      },
      "source": [
        "# CAPSTONE PROJECT\n",
        "\n",
        "Our training script begins with a selection of imports. These include:\n",
        "\n",
        "config: The configuration file consisting of paths and hyperparameters\n",
        "\n",
        "VGG16: The CNN architecture to serve as the base network for our fine tuning approach\n",
        "\n",
        "tf.keras: Imports from TensorFlow/Keras consisting of layer types, optimizers, and image loading/preprocessing routines\n",
        "\n",
        "train_test_split: Scikit-learn’s convenience utility for slicing our network into training and testing subsets\n",
        "\n",
        "matplotlib: Python’s de facto plotting package\n",
        "\n",
        "numpy: Python’s standard numerical processing library\n",
        "\n",
        "cv2: OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckPVrt8k877-"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aM03IEXHID9"
      },
      "source": [
        "#import Car_model_config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XbLzOjIJiLJ"
      },
      "source": [
        "BASE_PATH = \"/content/drive/My Drive/Capstone Data\"\n",
        "TRAIN_IMAGES_PATH = os.path.sep.join([BASE_PATH, \"Car Images/Train Images\"])\n",
        "TEST_IMAGES_PATH = os.path.sep.join([BASE_PATH, \"Car Images/Test Images\"])\n",
        "TRAIN_ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"Annotations/Train Annotations.csv\"])\n",
        "TEST_ANNOTS_PATH = os.path.sep.join([BASE_PATH, \"Annotations/Test Annotations.csv\"])\n",
        "CAR_NAMES_MAKE_DICT = os.path.sep.join([BASE_PATH, \"Car names and make.csv\"])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC-ymmL2-Sed",
        "outputId": "5eddd74d-1578-488d-cb91-4fc348fe6658"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgmN84eN-eYd"
      },
      "source": [
        "# load the contents of the CSV annotations file\n",
        "\n",
        "# initialize the list of data (images), our target output predictions\n",
        "# (bounding box coordinates), along with the filenames of the\n",
        "# individual images\n",
        "data = []\n",
        "targets = []\n",
        "trainfilenames = []\n",
        "testfilenames = []\n",
        "labels = []\n",
        "bboxes = []\n",
        "trainimagePaths = []\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQfWV9I4SEA-"
      },
      "source": [
        "import pandas as pd \n",
        "car_map = pd.read_csv(CAR_NAMES_MAKE_DICT)\n",
        "car_map=car_map.set_index('Cars')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgVCGjlQSp_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "c0c72b8c-4d06-4e40-9c93-397cdfa96263"
      },
      "source": [
        "car_map.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Numbers</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cars</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AM General Hummer SUV 2000</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acura RL Sedan 2012</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acura TL Sedan 2012</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acura TL Type-S 2008</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acura TSX Sedan 2012</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Class Numbers\n",
              "Cars                                     \n",
              "AM General Hummer SUV 2000              0\n",
              "Acura RL Sedan 2012                     1\n",
              "Acura TL Sedan 2012                     2\n",
              "Acura TL Type-S 2008                    3\n",
              "Acura TSX Sedan 2012                    4"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TrvyoKOTO2P"
      },
      "source": [
        "#Notuseful\n",
        "\n",
        "#def add_one(x):\n",
        "#\treturn x + 1\n",
        "\n",
        "#car_map[\"Class Numbers\"] = car_map[\"Class Numbers\"].apply(add_one)\n",
        "#car_map.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_HAm_ikTkRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d4cc13-7452-4e37-df81-ec271bbd5572"
      },
      "source": [
        "car_map_dict=car_map.to_dict('index')\n",
        "list(car_map_dict.items())[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('AM General Hummer SUV 2000', {'Class Numbers': 0}),\n",
              " ('Acura RL Sedan 2012', {'Class Numbers': 1}),\n",
              " ('Acura TL Sedan 2012', {'Class Numbers': 2}),\n",
              " ('Acura TL Type-S 2008', {'Class Numbers': 3}),\n",
              " ('Acura TSX Sedan 2012', {'Class Numbers': 4})]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL8sWNBnWnaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbf3f50-82d0-43e2-d8ce-f5bb04a23e69"
      },
      "source": [
        "#fetch a key based on value passed - we need this to build our image paths\n",
        "print(list(car_map_dict.keys())[173])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ram C-V Cargo Van Minivan 2012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8SRK2Scs-B"
      },
      "source": [
        "\n",
        "import csv\n",
        "with open(TRAIN_ANNOTS_PATH, newline='') as file:\n",
        "    \n",
        "    reader = csv.reader(file, delimiter = ' ')\n",
        "      \n",
        "    # store the headers in a separate variable,\n",
        "    # move the reader object to point on the next row\n",
        "    headings = next(reader)\n",
        "      \n",
        "    # output list to store all rows\n",
        "    Output = []\n",
        "    for row in reader:\n",
        "        Output.append(row[:])\n",
        "  \n",
        "for row in Output:\n",
        "    row = str(row)\n",
        "    row = row.split(\",\")\n",
        "    (filename, startX, startY, endX, endY, label) = row\n",
        "    filename = filename.split(\"'\",1)\n",
        "    fname = filename[1]\n",
        "    label = label.split(\"'\", 1)\n",
        "    lbl = int(label[0]) -1\n",
        "    keyName = list(car_map_dict.keys())[lbl]\n",
        "    imagePathtrain = os.path.sep.join([TRAIN_IMAGES_PATH, keyName, fname])\n",
        "\n",
        "    image = cv2.imread(imagePathtrain)\n",
        "    (h, w) = image.shape[:2]\n",
        "\t\t# scale the bounding box coordinates relative to the spatial\n",
        "\t\t# dimensions of the input image\n",
        "    startX = float(startX) / w\n",
        "    startY = float(startY) / h\n",
        "    endX = float(endX) / w\n",
        "    endY = float(endY) / h\n",
        "\t\t# load the image and preprocess it\n",
        "    image = load_img(imagePathtrain, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "\t\t# update our list of data, targets, and filenames\n",
        "\n",
        "    data = np.append(data, image)\n",
        "    labels = np.append(labels, lbl)\n",
        "    bboxes = np.append(bboxes, (startX, startY, endX, endY))\n",
        "    trainimagePaths = np.append(trainimagePaths,imagePathtrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSt4chrC0yT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "17508ee8-7d9f-40b3-f396-6671347c8e48"
      },
      "source": [
        "\n",
        " \n",
        "# convert the data, class labels, bounding boxes, and image paths to\n",
        "# NumPy arrays, scaling the input pixel intensities from the range\n",
        "# [0, 255] to [0, 1]\n",
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "labels = np.array(labels)\n",
        "bboxes = np.array(bboxes, dtype=\"float32\")\n",
        "imagePaths = np.array(imagePaths)\n",
        "# perform one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "# only there are only two labels in the dataset, then we need to use\n",
        "# Keras/TensorFlow's utility function as well\n",
        "if len(lb.classes_) == 2:\n",
        "\tlabels = to_categorical(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-811122d33293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# perform one-hot encoding on the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# only there are only two labels in the dataset, then we need to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Keras/TensorFlow's utility function as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    296\u001b[0m             )\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has 0 samples: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y has 0 samples: array([], dtype=float64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwCO1GQS2daL"
      },
      "source": [
        "####to do......\n",
        "# derive the path to the input image, load the image (in OpenCV\n",
        "# format), and grab its dimensions\n",
        "imagePathtest = os.path.sep.join([config.IMAGES_PATH, filename])\n",
        "image = cv2.imread(imagePathtest)\n",
        "(h, w) = image.shape[:2]\n",
        "# scale the bounding box coordinates relative to the spatial\n",
        "# dimensions of the input image\n",
        "startX = float(startX) / w\n",
        "startY = float(startY) / h\n",
        "endX = float(endX) / w\n",
        "endY = float(endY) / h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YL1pIoc2iao"
      },
      "source": [
        "####to do......\n",
        "# load the image and preprocess it\n",
        "image = load_img(imagePathtest, target_size=(224, 224))\n",
        "image = img_to_array(image)\n",
        "# update our list of data, targets, and filenames\n",
        "data.append(image)\n",
        "targets.append((startX, startY, endX, endY))\n",
        "testfilenames.append(filename)\n",
        " \n",
        "# convert the data and targets to NumPy arrays, scaling the input\n",
        "# pixel intensities from the range [0, 255] to [0, 1]\n",
        "data = np.array(data, dtype=\"float32\") / 255.0\n",
        "targets = np.array(targets, dtype=\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZIVH-zG20Fh"
      },
      "source": [
        "####to do......\n",
        "# write the testing filenames to disk so that we can use then\n",
        "# when evaluating/testing our bounding box regressor\n",
        "print(\"[INFO] saving testing filenames...\")\n",
        "f = open(config.TEST_FILENAMES, \"w\")\n",
        "f.write(\"\\n\".join(testfilenames))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQGDqBtS2iji"
      },
      "source": [
        "####to do......\n",
        "# load the VGG16 network, ensuring the head FC layers are left off\n",
        "vgg = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# freeze all VGG layers so they will *not* be updated during the\n",
        "# training process\n",
        "vgg.trainable = False\n",
        "# flatten the max-pooling output of VGG\n",
        "flatten = vgg.output\n",
        "flatten = Flatten()(flatten)\n",
        "# construct a fully-connected layer header to output the predicted\n",
        "# bounding box coordinates\n",
        "bboxHead = Dense(128, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
        "# construct the model we will fine-tune for bounding box regression\n",
        "model = Model(inputs=vgg.input, outputs=bboxHead)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PkrOZel3F7e"
      },
      "source": [
        "####to do......\n",
        "# initialize the optimizer, compile the model, and show the model\n",
        "# summary\n",
        "opt = Adam(lr=config.INIT_LR)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "print(model.summary())\n",
        "# train the network for bounding box regression\n",
        "print(\"[INFO] training bounding box regressor...\")\n",
        "H = model.fit(\n",
        "\ttrainImages, trainTargets,\n",
        "\tvalidation_data=(testImages, testTargets),\n",
        "\tbatch_size=config.BATCH_SIZE,\n",
        "\tepochs=config.NUM_EPOCHS,\n",
        "\tverbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}