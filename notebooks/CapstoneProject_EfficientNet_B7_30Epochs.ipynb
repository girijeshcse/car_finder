{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-QnlWPyEDIu"
      },
      "source": [
        "#### Connect To Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8S1y53v0IYp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8Dgw6KoZjV0"
      },
      "outputs": [],
      "source": [
        "#cd /content/drive/MyDrive/MachineLearning/CapstoneProject"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNraI2Y0EJzQ"
      },
      "source": [
        "## Reading required files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQrfFk1AEN7S"
      },
      "source": [
        "#### Reading Train Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jIQyh5AZvKq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "annotationsTrainDF = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset/Annotations/Train Annotations.csv\")\n",
        "annotationsTrainDF.rename(columns = {'Bounding Box coordinates':'xmin'}, inplace = True)\n",
        "annotationsTrainDF.rename(columns = {'Unnamed: 2':'ymin'}, inplace = True)\n",
        "annotationsTrainDF.rename(columns = {'Unnamed: 3':'xmax'}, inplace = True)\n",
        "annotationsTrainDF.rename(columns = {'Unnamed: 4':'ymax'}, inplace = True)\n",
        "annotationsTrainDF.rename(columns = {'Image class':'Image_class'}, inplace = True)\n",
        "annotationsTrainDF.rename(columns = {'Image Name':'Image_Name'}, inplace = True)\n",
        "annotationsTrainDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd0epOVQEU-v"
      },
      "source": [
        "#### Reading Test Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wrb1lropupo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "annotationsTestDF = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset/Annotations/Test Annotation.csv\")\n",
        "annotationsTestDF.rename(columns = {'Bounding Box coordinates':'xmin'}, inplace = True)\n",
        "annotationsTestDF.rename(columns = {'Unnamed: 2':'ymin'}, inplace = True)\n",
        "annotationsTestDF.rename(columns = {'Unnamed: 3':'xmax'}, inplace = True)\n",
        "annotationsTestDF.rename(columns = {'Unnamed: 4':'ymax'}, inplace = True)\n",
        "annotationsTestDF.rename(columns = {'Image class':'Image_class'}, inplace = True)\n",
        "annotationsTestDF.rename(columns = {'Image Name':'Image_Name'}, inplace = True)\n",
        "annotationsTestDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RprAAr7yEYRc"
      },
      "source": [
        "## Image Segregation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWthBmRZEmyK"
      },
      "source": [
        "#### Using Split-folder to create train and validation files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asGzWxupuvtn"
      },
      "outputs": [],
      "source": [
        "# pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7WOJzp_uxzL"
      },
      "outputs": [],
      "source": [
        "# import splitfolders # or import splitfolders\n",
        "# input_folder = \"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images//Train Images/\"\n",
        "# output = \"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Split/\" #where you want the split datasets saved. one will be created if it does not exist or none is set\n",
        "\n",
        "# splitfolders.ratio(input_folder, output=output, seed=42, ratio=(.8, .2)) # ratio of split are in order of train/val/test. You can change to whatever you want. For train/val sets only, you could do .75, .25 for example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muSE7GbKJpQO"
      },
      "source": [
        "## Creating data required for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2sc96jnFJHS"
      },
      "source": [
        "#### Creating list containing files and folder names for training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CclkNe2jvdPb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "#/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Samples/Jeep Liberty SUV 2012/00271.jpg\n",
        "trainDataSetPath=\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Split/train/*/*\"\n",
        "#reading png files in the path\n",
        "trainList = glob.glob(trainDataSetPath)\n",
        "print(trainList)\n",
        "\n",
        "trainListPaths = []\n",
        "for fileandFolder in trainList:\n",
        "  lList = fileandFolder.split(\"/\")[-2:]\n",
        "  trainListPaths.append(lList)\n",
        "\n",
        "print(len(trainListPaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3fEnSLHi-7"
      },
      "source": [
        "#### Creating list containing files and folder names for Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHGS66anZvOO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "#/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Samples/Jeep Liberty SUV 2012/00271.jpg\n",
        "validationDatasetPath=\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Split/val/*/*\"\n",
        "#reading png files in the path\n",
        "validationList = glob.glob(validationDatasetPath)\n",
        "print(validationList)\n",
        "\n",
        "validationListPaths = []\n",
        "for fileandFolder in validationList:\n",
        "  lList = fileandFolder.split(\"/\")[-2:]\n",
        "  validationListPaths.append(lList)\n",
        "\n",
        "print(len(validationListPaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJjqgmZkHn05"
      },
      "source": [
        "#### Creating list containing files and folder names for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1h4s-Riqbxn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "\n",
        "#/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Samples/Jeep Liberty SUV 2012/00271.jpg\n",
        "testDataSetPath=\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset/Car Images/Test Images/*/*\"\n",
        "#reading png files in the path\n",
        "testList = glob.glob(testDataSetPath)\n",
        "print(testList)\n",
        "\n",
        "testListPaths = []\n",
        "for fileandFolder in testList:\n",
        "  lList = fileandFolder.split(\"/\")[-2:]\n",
        "  testListPaths.append(lList)\n",
        "\n",
        "print(len(testListPaths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkzs7H3RHyD0"
      },
      "source": [
        "#### Creating Training dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX0NcPFyHuW4"
      },
      "outputs": [],
      "source": [
        "dfTrain = pd.DataFrame(trainListPaths, columns = ['carName','imageName'])\n",
        "dfTrain['carModel'] = dfTrain['carName'].str[-4:]\n",
        "dfTrain['carModel_1'] = dfTrain['carName'].str[:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329Muh_0BXNv"
      },
      "outputs": [],
      "source": [
        "dfTrain[['carName','carModel','carModel_1','imageName']].head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMYGq8O-HyeX"
      },
      "source": [
        "#### Creating Validation dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YE2dyEXZ93_"
      },
      "outputs": [],
      "source": [
        "dfValidation = pd.DataFrame(validationListPaths, columns = ['carName','imageName'])\n",
        "dfValidation['carModel'] = dfValidation['carName'].str[-4:]\n",
        "dfValidation['carModel_1'] = dfValidation['carName'].str[:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-3dsbGzBZM2"
      },
      "outputs": [],
      "source": [
        "dfValidation[['carName','carModel','carModel_1','imageName']].head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsWaZsCtHzPM"
      },
      "source": [
        "#### Creating Testing dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHMxzerCHwCI"
      },
      "outputs": [],
      "source": [
        "dfTest = pd.DataFrame(testListPaths, columns = ['carName','imageName'])\n",
        "dfTest['carModel'] = dfTest['carName'].str[-4:]\n",
        "dfTest['carModel_1'] = dfTest['carName'].str[:-4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNps-l1grOOV"
      },
      "outputs": [],
      "source": [
        "dfTest[['carName','carModel','carModel_1','imageName']].head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pBWLIk2JCBl"
      },
      "source": [
        "#### Merging train dataframe with annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6YBNry3ZvRY"
      },
      "outputs": [],
      "source": [
        "train_df = dfTrain.merge(annotationsTrainDF, how='inner', left_on='imageName', right_on='Image_Name')\n",
        "train_df = train_df.assign(image_path='/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Split/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQUBVcRFCGBi"
      },
      "outputs": [],
      "source": [
        "train_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fWr5SkJIoB"
      },
      "source": [
        "#### Merging Validation dataframe with annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yESVCYCXdJ1"
      },
      "outputs": [],
      "source": [
        "val_df = dfValidation.merge(annotationsTrainDF, how='inner', left_on='imageName', right_on='Image_Name')\n",
        "val_df = val_df.assign(image_path='/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Split/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIrALnk9wNuh"
      },
      "outputs": [],
      "source": [
        "val_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txj7eRthJJ6x"
      },
      "source": [
        "#### Merging test dataframe with annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldHi9QifrjwL"
      },
      "outputs": [],
      "source": [
        "test_df = dfTest.merge(annotationsTestDF, how='inner', left_on='imageName', right_on='Image_Name')\n",
        "test_df = test_df.assign(image_path='/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset/Car Images/Test Images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wbP8OZqwPro"
      },
      "outputs": [],
      "source": [
        "test_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1O36y2vKWBY"
      },
      "source": [
        "#### Checking basic details of dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAeAKt-awnsQ"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMFRTieXyUzY"
      },
      "outputs": [],
      "source": [
        "val_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l2mBll6VBBi"
      },
      "outputs": [],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9bhXLHQLBHC"
      },
      "source": [
        "#### Label encoding the car names for classification purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9VSL5qEYlbP"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "# label_encoder object knows how to understand word labels.\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "train_df['le_carName']= label_encoder.fit_transform(train_df['carName'])\n",
        "val_df['le_carName']= label_encoder.fit_transform(val_df['carName'])\n",
        "test_df['le_carName']= label_encoder.fit_transform(test_df['carName'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxzM8TI3s5bP"
      },
      "source": [
        "#### Extracting the height and width of the images from Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viSWNOnx5qlQ"
      },
      "outputs": [],
      "source": [
        "## from matplotlib import pyplot as plt\n",
        "## import cv2\n",
        "## import numpy as np\n",
        "## import pandas as pd\n",
        "\n",
        "## h = []\n",
        "## w =[]\n",
        "\n",
        "## mypath=\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset_1/Dataset/Car Images/Train Images/\"\n",
        "\n",
        "## for row in dfMerged.itertuples(index=False, name=None):\n",
        "##   # print(config.IMAGES_PATH + \"/\" + row[0] + \"/\" + row[1])\n",
        "##   imagePath = (mypath  + \"/\" + row[0] + \"/\" + row[1])#os.path.sep.join([config.IMAGES_PATH, filename])\n",
        "##   image = cv2.imread(imagePath)\n",
        "##   h.append(image.shape[:2][0])\n",
        "##   w.append(image.shape[:2][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PenJGqYkLh_H"
      },
      "source": [
        "#### Extracting the height and width of the images from Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vum1APflcNAG"
      },
      "outputs": [],
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# h = []\n",
        "# w =[]\n",
        "\n",
        "# mypath=\"/content/drive/MyDrive/MachineLearning/CapstoneProject/Dataset/Car Images/Test Images\"\n",
        "\n",
        "# for row in test_df[['carName','imageName']].itertuples(index=False, name=None):\n",
        "#   # print(config.IMAGES_PATH + \"/\" + row[0] + \"/\" + row[1])\n",
        "#   imagePath = (mypath  + \"/\" + row[0] + \"/\" + row[1])#os.path.sep.join([config.IMAGES_PATH, filename])\n",
        "#   image = cv2.imread(imagePath)\n",
        "#   h.append(image.shape[:2][0])\n",
        "#   w.append(image.shape[:2][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtG_FR30cuae"
      },
      "outputs": [],
      "source": [
        "# dfTest['Height'] = h\n",
        "# dfTest['Width'] = w\n",
        "# dfTest.to_csv(\"/content/drive/MyDrive/MachineLearning/CapstoneProject/test_8041_images.csv\")\n",
        "# dfTest_W_H = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/CapstoneProject/train_8144_images.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjCCsQ_PPXt-"
      },
      "source": [
        "#### Creating Train and validation dataframe with width and height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu8-6gDc50oh"
      },
      "outputs": [],
      "source": [
        "dfTrain_W_H = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/CapstoneProject/train_8144_images.csv\")\n",
        "dfTrain_W_H = dfTrain_W_H[['Height','Width','Image_Name']]\n",
        "train_df = train_df.merge(dfTrain_W_H, how='inner', left_on='imageName', right_on='Image_Name')\n",
        "train_df['File'] = train_df['image_path'] + \"/\" + train_df['carName'] + \"/\" + train_df['imageName']\n",
        "train_df.rename(columns = {'Image_class':'Class'}, inplace = True)\n",
        "train_df.rename(columns = {'le_carName':'Label'}, inplace = True)\n",
        "train_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQw3V389zFzi"
      },
      "outputs": [],
      "source": [
        "val_df = val_df.merge(dfTrain_W_H, how='inner', left_on='imageName', right_on='Image_Name')\n",
        "val_df['File'] = val_df['image_path'] + \"/\" + val_df['carName'] + \"/\" + val_df['imageName']\n",
        "val_df.rename(columns = {'Image_class':'Class'}, inplace = True)\n",
        "val_df.rename(columns = {'le_carName':'Label'}, inplace = True)\n",
        "val_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdvPFvuePojz"
      },
      "source": [
        "#### Creating Test dataframe with width and height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3fB2B1Sa79f"
      },
      "outputs": [],
      "source": [
        "test_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5tb1hPo09NP"
      },
      "outputs": [],
      "source": [
        "dfTest_W_H = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/CapstoneProject/test_8041_images.csv\")\n",
        "# dfTest_W_H\n",
        "dfTest_W_H = dfTest_W_H[['Height','Width','imageName']]\n",
        "test_df = test_df.merge(dfTest_W_H, how='inner', left_on='imageName', right_on='imageName')\n",
        "test_df['File'] = test_df['image_path'] + \"/\" + test_df['carName'] + \"/\" + test_df['imageName']\n",
        "test_df.rename(columns = {'Image_class':'Class'}, inplace = True)\n",
        "test_df.rename(columns = {'le_carName':'Label'}, inplace = True)\n",
        "test_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10O2fqs_sahR"
      },
      "source": [
        "## Display sample data with bounding boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eZShbYtsjwg"
      },
      "source": [
        "#### Display sample data for Train set images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8xe82C71Esi"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Pickup a random image number\n",
        "img_num = np.random.randint(0, train_df.shape[0])\n",
        "#Read the image and draw a rectangle as per bounding box information\n",
        "img = cv2.imread(train_df.loc[img_num,'File'])\n",
        "img = cv2.resize(img,(224, 224))\n",
        "w = train_df.loc[img_num, 'Width']\n",
        "h = train_df.loc[img_num, 'Height']\n",
        "x_ratio = 224/w\n",
        "y_ratio = 224/h\n",
        "cv2.rectangle(img, \n",
        "             (int(train_df.loc[img_num, 'xmin']*x_ratio),int(train_df.loc[img_num, 'ymin']*y_ratio)),\n",
        "             (int(train_df.loc[img_num, 'xmax']*x_ratio),int(train_df.loc[img_num, 'ymax']*y_ratio)), \n",
        "             (0,255,0),\n",
        "             2)\n",
        "\n",
        "#Convert BGR format (used by opencv to RGB format used by matplotlib)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Draw image using matplotlib\n",
        "plt.suptitle(train_df.loc[img_num, 'Class'])\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnv05wRusqQL"
      },
      "source": [
        "#### Display sample data for Validation set images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKJg--y70jVL"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Pickup a random image number\n",
        "img_num = np.random.randint(0, val_df.shape[0])\n",
        "#Read the image and draw a rectangle as per bounding box information\n",
        "img = cv2.imread(val_df.loc[img_num,'File'])\n",
        "img = cv2.resize(img,(224, 224))\n",
        "w = val_df.loc[img_num, 'Width']\n",
        "h = val_df.loc[img_num, 'Height']\n",
        "x_ratio = 224/w\n",
        "y_ratio = 224/h\n",
        "cv2.rectangle(img, \n",
        "             (int(val_df.loc[img_num, 'xmin']*x_ratio),int(val_df.loc[img_num, 'ymin']*y_ratio)),\n",
        "             (int(val_df.loc[img_num, 'xmax']*x_ratio),int(val_df.loc[img_num, 'ymax']*y_ratio)), \n",
        "             (0,255,0),\n",
        "             2)\n",
        "\n",
        "#Convert BGR format (used by opencv to RGB format used by matplotlib)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Draw image using matplotlib\n",
        "plt.suptitle(val_df.loc[img_num, 'Class'])\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoJrjLrssOh"
      },
      "source": [
        "#### Display sample data for Test set images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mxlqaxu0yV0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Pickup a random image number\n",
        "img_num = np.random.randint(0, test_df.shape[0])\n",
        "#Read the image and draw a rectangle as per bounding box information\n",
        "img = cv2.imread(test_df.loc[img_num,'File'])\n",
        "img = cv2.resize(img,(224, 224))\n",
        "w = test_df.loc[img_num, 'Width']\n",
        "h = test_df.loc[img_num, 'Height']\n",
        "x_ratio = 224/w\n",
        "y_ratio = 224/h\n",
        "cv2.rectangle(img, \n",
        "             (int(test_df.loc[img_num, 'xmin']*x_ratio),int(test_df.loc[img_num, 'ymin']*y_ratio)),\n",
        "             (int(test_df.loc[img_num, 'xmax']*x_ratio),int(test_df.loc[img_num, 'ymax']*y_ratio)), \n",
        "             (0,255,0),\n",
        "             2)\n",
        "\n",
        "#Convert BGR format (used by opencv to RGB format used by matplotlib)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#Draw image using matplotlib\n",
        "plt.suptitle(test_df.loc[img_num, 'Class'])\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Gzmfkbd1gmJ"
      },
      "outputs": [],
      "source": [
        "# asdjkhasdjkhjk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pxa95DT6gsU"
      },
      "source": [
        "#### Checking number of classes in each dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn2qll2cHLoW"
      },
      "outputs": [],
      "source": [
        "#Create a dictionary to hold label and corresponding class name\n",
        "num_classes_train = train_df['Label'].unique()\n",
        "print(len(num_classes_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtZQ-WY60_AE"
      },
      "outputs": [],
      "source": [
        "#Create a dictionary to hold label and corresponding class name\n",
        "num_classes_val = val_df['Label'].unique()\n",
        "print(len(num_classes_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viL78uk7szxE"
      },
      "outputs": [],
      "source": [
        "#Create a dictionary to hold label and corresponding class name\n",
        "num_classes_test = test_df['Label'].unique()\n",
        "label_class_dict = dict(zip(test_df['Label'], test_df['carName']))\n",
        "print(len(num_classes_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy17Ose_6nrS"
      },
      "outputs": [],
      "source": [
        "num_classes = train_df['Label'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbePE8pDUap"
      },
      "source": [
        "## Build a Batch Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJHj-NNvEhpa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8RGtJJKEmPK"
      },
      "outputs": [],
      "source": [
        "img_size = 224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG9qxvqfDXgJ"
      },
      "outputs": [],
      "source": [
        "def batch_generator(df, batch_size=32):\n",
        "\n",
        "    while True:\n",
        "\n",
        "        #Create indexes\n",
        "        image_nums = np.random.randint(0,df.shape[0], size=batch_size)\n",
        "\n",
        "        #Create empty arrays\n",
        "        #1. To hold image input\n",
        "        batch_images = np.zeros(shape=(batch_size, img_size, img_size, 3))\n",
        "\n",
        "        #Classification Labels \n",
        "        batch_labels = np.zeros(shape=(batch_size, len(num_classes)))\n",
        "        \n",
        "        #Regression labels - 4 numbers per example image\n",
        "        batch_bboxes = np.zeros(shape=(batch_size, 4))\n",
        "        \n",
        "\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            #Read image and resize\n",
        "            img = tf.keras.preprocessing.image.load_img(df.loc[image_nums[i], 'File'], \n",
        "                                                        target_size=(img_size, img_size))\n",
        "            \n",
        "            #Conver to numpy array\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "            #Update batch\n",
        "            batch_images[i] = img_array\n",
        "\n",
        "            #Read image classification label & convert to one hot vector\n",
        "            cl_label = df.loc[image_nums[i], 'Label']\n",
        "            cl_label = tf.keras.utils.to_categorical(cl_label, num_classes=len(num_classes))\n",
        "            batch_labels[i] = cl_label\n",
        "\n",
        "            #Read and resize bounding box co-ordinates\n",
        "            img_width = df.loc[image_nums[i], 'Width']\n",
        "            img_height = df.loc[image_nums[i], 'Height']\n",
        "            \n",
        "            xmin = df.loc[image_nums[i], 'xmin'] * img_size/img_width\n",
        "            xmax = df.loc[image_nums[i], 'xmax'] * img_size/img_width\n",
        "\n",
        "            ymin = df.loc[image_nums[i], 'ymin'] * img_size/img_height\n",
        "            ymax = df.loc[image_nums[i], 'ymax'] * img_size/img_height\n",
        "\n",
        "            #We will ask model to predict xmin, ymin, width and height of bounding box\n",
        "            batch_bboxes[i] = [xmin, ymin, xmax-xmin, ymax-ymin]\n",
        "\n",
        "        #Normalize batch images as per Pre-trained model to be used\n",
        "        for i in range(batch_size):\n",
        "            batch_images[i] = tf.keras.applications.efficientnet.preprocess_input(batch_images[i])\n",
        "        \n",
        "        #Make bounding boxes (x, y, w, h) as numbers between 0 and 1 - this seems to work better\n",
        "        batch_bboxes = batch_bboxes/img_size\n",
        "\n",
        "        #Return batch - use yield function to make it a python generator\n",
        "        yield batch_images, [batch_labels, batch_bboxes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8lgxrqg6tnH"
      },
      "source": [
        "#### Checking the output of the batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2Fw6l71Sig-"
      },
      "outputs": [],
      "source": [
        "gen = batch_generator(train_df, batch_size=2)\n",
        "X, y = next(gen)\n",
        "print(X.shape)\n",
        "print(y[0].shape, y[1].shape)\n",
        "print(y)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "ll1111 = []\n",
        "# label_encoder.inverse_transform(y[0][0])\n",
        "for i in range(0,len(y[0])):\n",
        "  y1 = int(np.argmax(y[0][i], axis=-1))\n",
        "  ll1111.extend([y1])\n",
        "\n",
        "print(len(ll1111))\n",
        "print(label_encoder.inverse_transform(ll1111))\n",
        "\n",
        "plt.figure(figsize =(10, 4))\n",
        "\n",
        "#subplot(r,c) provide the no. of rows and columns\n",
        "f, axarr = plt.subplots(len(y[0]),1) \n",
        "\n",
        "for i in range(0,len(y[0])):\n",
        "  axarr[i].imshow(X[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Hxm4_c075t"
      },
      "outputs": [],
      "source": [
        "gen = batch_generator(val_df, batch_size=2)\n",
        "X, y = next(gen)\n",
        "print(X.shape)\n",
        "print(y[0].shape, y[1].shape)\n",
        "print(y)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "ll1111 = []\n",
        "# label_encoder.inverse_transform(y[0][0])\n",
        "for i in range(0,len(y[0])):\n",
        "  y1 = int(np.argmax(y[0][i], axis=-1))\n",
        "  ll1111.extend([y1])\n",
        "\n",
        "print(len(ll1111))\n",
        "print(label_encoder.inverse_transform(ll1111))\n",
        "\n",
        "plt.figure(figsize =(10, 4))\n",
        "\n",
        "#subplot(r,c) provide the no. of rows and columns\n",
        "f, axarr = plt.subplots(len(y[0]),1) \n",
        "\n",
        "for i in range(0,len(y[0])):\n",
        "  axarr[i].imshow(X[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cylN-wK8SqEB"
      },
      "outputs": [],
      "source": [
        "gen = batch_generator(test_df, batch_size=2)\n",
        "X, y = next(gen)\n",
        "print(X.shape)\n",
        "print(y[0].shape, y[1].shape)\n",
        "print(y)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "ll1111 = []\n",
        "# label_encoder.inverse_transform(y[0][0])\n",
        "for i in range(0,len(y[0])):\n",
        "  y1 = int(np.argmax(y[0][i], axis=-1))\n",
        "  ll1111.extend([y1])\n",
        "\n",
        "print(len(ll1111))\n",
        "print(label_encoder.inverse_transform(ll1111))\n",
        "\n",
        "plt.figure(figsize =(10, 4))\n",
        "\n",
        "#subplot(r,c) provide the no. of rows and columns\n",
        "f, axarr = plt.subplots(len(y[0]),1) \n",
        "\n",
        "for i in range(0,len(y[0])):\n",
        "  axarr[i].imshow(X[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6gp87mgf3ou"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFGPcGaMJt9-"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVXicG2xKBoq"
      },
      "source": [
        "#### Load Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBPc2TXuJn5m"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.applications.efficientnet.EfficientNetB7(include_top=False, #Do not include FC layer at the end\n",
        "                                       input_shape=(224, 224, 3),\n",
        "                                       weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfb-JkRaJps_"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z30I35deKR2_"
      },
      "source": [
        "#### Un-Freeze Few layers of Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G00NdDiMLkx"
      },
      "outputs": [],
      "source": [
        "len(model.layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knDlNjFkp3Cu"
      },
      "outputs": [],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCTzSXyTp5-Y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsafx9zlKEzA"
      },
      "outputs": [],
      "source": [
        "# for layer in model.layers:\n",
        "#     layer.trainable = True\n",
        "\n",
        "# # # #Set pre-trained model layers to not trainable\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "#######Unfreezing all layers after layer#\n",
        "for layer in model.layers[0:351]:\n",
        "    layer.trainable = False\n",
        "    # print(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itYAVviBgJW4"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s77uFZ5gh-25"
      },
      "outputs": [],
      "source": [
        "model.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ochVcQl_Knjg"
      },
      "source": [
        "#### Add Final layers to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrdSJfSFKXIH"
      },
      "outputs": [],
      "source": [
        "#get Output layer of Pre-trained model\n",
        "x1 = model.output\n",
        "\n",
        "#Flatten the output to feed to Dense layer\n",
        "x2 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
        "\n",
        "#Add one Dense layer\n",
        "x3 = tf.keras.layers.Dense(2560, activation='relu')(x2)\n",
        "\n",
        "#Batch Norm\n",
        "x5 = tf.keras.layers.BatchNormalization()(x3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSsesgHCKuq0"
      },
      "source": [
        "#### Build layer for Classification Label output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUyBwuxlKt67"
      },
      "outputs": [],
      "source": [
        "#Classification\n",
        "label_output = tf.keras.layers.Dense(len(num_classes), \n",
        "                                     activation='softmax', \n",
        "                                     name='class_op')(x5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bksL8On7tZ5f"
      },
      "outputs": [],
      "source": [
        "label_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smOcT5VLK6BA"
      },
      "source": [
        "#### Build layer for bounding box output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujk5IXzIK9O1"
      },
      "outputs": [],
      "source": [
        "#Regression\n",
        "bbox_output = tf.keras.layers.Dense(4, \n",
        "                                    activation='sigmoid', \n",
        "                                    name='reg_op')(x5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9roF0YmBuQ4a"
      },
      "outputs": [],
      "source": [
        "bbox_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSvjuIa2LlOY"
      },
      "source": [
        "#### Finalize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3frSPd3Lj7i"
      },
      "outputs": [],
      "source": [
        "#Non Sequential model as it has two different outputs\n",
        "final_model = tf.keras.models.Model(inputs=model.input, #Pre-trained model input as input layer\n",
        "                                    outputs=[label_output,bbox_output]) #Output layer added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvXbMqx_sOCh"
      },
      "outputs": [],
      "source": [
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KpqhepoiAfe"
      },
      "source": [
        "#### Define function to calculate IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ww0PFGg6ql3C"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(y_true, y_pred):\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Input:\n",
        "    Keras provides the input as numpy arrays with shape (batch_size, num_columns).\n",
        "    \n",
        "    Arguments:\n",
        "    y_true -- first box, numpy array with format [x, y, width, height, conf_score]\n",
        "    y_pred -- second box, numpy array with format [x, y, width, height, conf_score]\n",
        "    x any y are the coordinates of the top left corner of each box.\n",
        "    \n",
        "    Output: IoU of type float32. (This is a ratio. Max is 1. Min is 0.)\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for i in range(0,y_true.shape[0]):\n",
        "    \n",
        "        # set the types so we are sure what type we are using\n",
        "        y_true = np.array(y_true, dtype=np.float32)\n",
        "        y_pred = np.array(y_pred, dtype=np.float32)\n",
        "\n",
        "        #print(y_true.shape)\n",
        "        #print(y_pred.shape)\n",
        "        # boxTrue\n",
        "        x_boxTrue_tleft = y_true[i,0]  # numpy index selection\n",
        "        y_boxTrue_tleft = y_true[i,1]\n",
        "        boxTrue_width = y_true[i,2]\n",
        "        boxTrue_height = y_true[i,3]\n",
        "        area_boxTrue = (boxTrue_width * boxTrue_height)\n",
        "\n",
        "        # boxPred\n",
        "        x_boxPred_tleft = y_pred[i,0]\n",
        "        y_boxPred_tleft = y_pred[i,1]\n",
        "        boxPred_width = y_pred[i,2]\n",
        "        boxPred_height = y_pred[i,3]\n",
        "        area_boxPred = (boxPred_width * boxPred_height)\n",
        "\n",
        "        # calculate the bottom right coordinates for boxTrue and boxPred\n",
        "\n",
        "        # boxTrue\n",
        "        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n",
        "        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n",
        "\n",
        "        # boxPred\n",
        "        x_boxPred_br = x_boxPred_tleft + boxPred_width\n",
        "        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n",
        "\n",
        "\n",
        "        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n",
        "\n",
        "        # boxInt - top left coords\n",
        "        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n",
        "        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n",
        "\n",
        "        # boxInt - bottom right coords\n",
        "        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n",
        "        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n",
        "\n",
        "        # Calculate the area of boxInt, i.e. the area of the intersection \n",
        "        # between boxTrue and boxPred.\n",
        "        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n",
        "        \n",
        "        \n",
        "        # Version 2 revision\n",
        "        area_of_intersection = \\\n",
        "        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n",
        "\n",
        "        iou = area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)\n",
        "\n",
        "\n",
        "        # This must match the type used in py_func\n",
        "        iou = np.array(iou, dtype=np.float32)\n",
        "        \n",
        "        # append the result to a list at the end of each loop\n",
        "        results.append(iou)\n",
        "    \n",
        "    # return the mean IoU score for the batch\n",
        "    return np.mean(results)\n",
        "\n",
        "\n",
        "\n",
        "def IoU(y_true, y_pred):\n",
        "    \n",
        "    # Note: the type float32 is very important. It must be the same type as the output from\n",
        "    # the python function above or you too may spend many late night hours \n",
        "    # trying to debug and almost give up.\n",
        "    \n",
        "    iou = tf.py_function(calculate_iou, [y_true, y_pred], tf.float32)\n",
        "\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfVR7QqYLyNz"
      },
      "outputs": [],
      "source": [
        "optimizerVar = tf.keras.optimizers.Adam()\n",
        "final_model.compile(optimizer=optimizerVar, \n",
        "                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n",
        "                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RQg_TeWL8CC"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLOR7EApL6cl"
      },
      "outputs": [],
      "source": [
        "#Create train and test generator\n",
        "batchsize = 64\n",
        "train_generator = batch_generator(train_df, batch_size=batchsize) #batchsize can be changed\n",
        "test_generator = batch_generator(val_df, batch_size=batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tehY-Ac2Yad"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/content/drive/MyDrive/MachineLearning/CapstoneProject/tempCSV/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_class_op_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGjtvmc_zaIh"
      },
      "outputs": [],
      "source": [
        "history_1 = final_model.fit(train_generator,\n",
        "                epochs=10,\n",
        "                steps_per_epoch= train_df.shape[0]//batchsize,validation_data=test_generator,\n",
        "                validation_steps = val_df.shape[0]//batchsize, callbacks=[model_checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " "
      ],
      "metadata": {
        "id": "uwgFRewuxNue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbonN5keWeVk"
      },
      "outputs": [],
      "source": [
        "acc = history_1.history['class_op_accuracy']\n",
        "val_acc = history_1.history['val_class_op_accuracy']\n",
        "\n",
        "iou = history_1.history['reg_op_IoU']\n",
        "val_iou = history_1.history['val_reg_op_IoU']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, iou, label='Training IOU')\n",
        "plt.plot(epochs_range, val_iou, label='Validation IOU')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation IOU')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmqypNf28WGS"
      },
      "outputs": [],
      "source": [
        "optimizerVar = tf.keras.optimizers.Adam(lr=0.0001)\n",
        "final_model.compile(optimizer=optimizerVar, \n",
        "                    loss={'reg_op':'mse', 'class_op':'categorical_crossentropy'},\n",
        "                    metrics={'reg_op':[IoU], 'class_op':['accuracy']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8xqseOz8fk0"
      },
      "outputs": [],
      "source": [
        "batchsize=16\n",
        "history_2 = final_model.fit(train_generator,\n",
        "                epochs=25,\n",
        "                initial_epoch=10,\n",
        "                steps_per_epoch= train_df.shape[0]//batchsize,validation_data=test_generator,\n",
        "                validation_steps = val_df.shape[0]//batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx3uHEFRS_Cz"
      },
      "outputs": [],
      "source": [
        "acc = history_2.history['class_op_accuracy']\n",
        "val_acc = history_2.history['val_class_op_accuracy']\n",
        "\n",
        "iou = history_2.history['reg_op_IoU']\n",
        "val_iou = history_2.history['val_reg_op_IoU']\n",
        "\n",
        "epochs_range = range(15)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, iou, label='Training IOU')\n",
        "plt.plot(epochs_range, val_iou, label='Validation IOU')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation IOU')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5msq1-6tX3lJ"
      },
      "outputs": [],
      "source": [
        "final_model.save('/content/drive/MyDrive/MachineLearning/CapstoneProject/savedModels/Cars_196_dataset_localization_Adam_EfficientNet_B7_Epoch30_V1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT_TJaPWX2PK"
      },
      "source": [
        "#### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyrMXl9EdiSt"
      },
      "outputs": [],
      "source": [
        "def predict_and_draw(image_num, df):\n",
        "\n",
        "    #Load image\n",
        "    img = tf.keras.preprocessing.image.load_img(df.loc[image_num, 'File'])\n",
        "    w, h = img.size\n",
        "\n",
        "    #Prepare input for model\n",
        "    #1. Resize image\n",
        "    img_resized = img.resize((img_size, img_size))\n",
        "    #2. Conver to array and make it a batch of 1\n",
        "    input_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "    input_array = np.expand_dims(input_array, axis=0)\n",
        "\n",
        "    #3. Normalize image data\n",
        "    input_array = tf.keras.applications.efficientnet.preprocess_input(input_array)\n",
        "\n",
        "    #Prediction\n",
        "    pred = final_model.predict(input_array)\n",
        "    #Get classification and regression predictions\n",
        "    label_pred, bbox_pred = pred[0][0], pred[1][0]\n",
        "    #Get Label with highest probability\n",
        "    pred_class = label_class_dict[np.argmax(label_pred)]\n",
        "\n",
        "    #Read actual label and bounding box\n",
        "    act_class = df.loc[image_num, 'Class']\n",
        "    act_class = df.loc[image_num, 'carName']\n",
        "    xmin, ymin, xmax, ymax = df.loc[image_num, ['xmin', 'ymin', 'xmax', 'ymax']]\n",
        "\n",
        "    print('Real Label :', act_class, '\\nPredicted Label: ', pred_class)\n",
        "    \n",
        "    #Draw bounding boxes - Actual (Red) and Predicted(Green)\n",
        "    img = cv2.imread(df.loc[image_num, 'File'])\n",
        "    \n",
        "    #Draw actual bounding box - Red\n",
        "    img = cv2.rectangle(img, (xmin, ymin), \n",
        "                        (xmax, ymax), (0,0,255), 3)\n",
        "    \n",
        "    #Draw predicted bounding box -  Green\n",
        "    img = cv2.rectangle(img, (int(bbox_pred[0]*w), int(bbox_pred[1]*h)), \n",
        "                        (int((bbox_pred[0]+bbox_pred[2])*w), int((bbox_pred[1]+bbox_pred[3])*h)), (0,255,0), 3\n",
        "                        )\n",
        "\n",
        "    #Display the picture\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "DH0bH4YiYZ4b"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "#Predict on Test Dataset\n",
        "for i in range(0,200):\n",
        "  image_num = np.random.randint(0, test_df.shape[0])\n",
        "  predict_and_draw(image_num, test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEvmvAJCHLdM"
      },
      "outputs": [],
      "source": [
        "testData_generator = batch_generator(test_df, batch_size=64)\n",
        "\n",
        "print('Evaluating')\n",
        "test_results = final_model.evaluate(testData_generator, batch_size = 32, steps = 250, workers = 2, use_multiprocessing = True, return_dict = True , verbose=1)\n",
        "print('\\nTest accuracy:', test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qljL2BOWDWa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3X_uZwFXHLUE"
      },
      "outputs": [],
      "source": [
        "# act_class = pd.DataFrame()\n",
        "# pred_class = pd.DataFrame()\n",
        "\n",
        "dataF = pd.DataFrame(columns=['Actual','Pred'])\n",
        "\n",
        "def predict_and_develop_dataFrame(image_num, df):\n",
        "\n",
        "    #Load image\n",
        "    img = tf.keras.preprocessing.image.load_img(df.loc[image_num, 'File'])\n",
        "    w, h = img.size\n",
        "\n",
        "    #Prepare input for model\n",
        "    #1. Resize image\n",
        "    img_resized = img.resize((img_size, img_size))\n",
        "    #2. Conver to array and make it a batch of 1\n",
        "    input_array = tf.keras.preprocessing.image.img_to_array(img_resized)\n",
        "    input_array = np.expand_dims(input_array, axis=0)\n",
        "\n",
        "    #3. Normalize image data\n",
        "    input_array = tf.keras.applications.efficientnet.preprocess_input(input_array)\n",
        "\n",
        "    #Prediction\n",
        "    pred = final_model.predict(input_array, use_multiprocessing = True, )\n",
        "    #Get classification and regression predictions\n",
        "    label_pred = pred[0][0]\n",
        "\n",
        "    #Read actual label \n",
        "    # act_class.append((df.loc[image_num, 'carName']).to_frame(), ignore_index = True)\n",
        "    # # pred_class.append(label_class_dict[np.argmax(label_pred)], ignore_index = True)\n",
        "    to_append = [df.loc[image_num, 'carName'], label_class_dict[np.argmax(label_pred)]]\n",
        "    \n",
        "    # print((to_append))\n",
        "    # print('Real Label :', df.loc[image_num, 'carName'], '\\nPredicted Label: ', label_class_dict[np.argmax(label_pred)])\n",
        "\n",
        "    df_length = len(dataF)\n",
        "    dataF.loc[df_length] = to_append"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSbgAita-X2H"
      },
      "outputs": [],
      "source": [
        " for i in range(0,8041):\n",
        "  predict_and_develop_dataFrame(i,test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn5P301UQSwY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = dataF['Actual']\n",
        "y_pred = dataF['Pred']\n",
        "target_names = dataF['Actual'].unique()\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nuy4Obbl631"
      },
      "source": [
        "  Above is the classification report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE82PNbBSfGR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "W-QnlWPyEDIu",
        "uQrfFk1AEN7S",
        "wd0epOVQEU-v",
        "BWthBmRZEmyK",
        "x2sc96jnFJHS",
        "ea3fEnSLHi-7",
        "OJjqgmZkHn05"
      ],
      "name": "CapstoneProject_EfficientNet_B7_30Epochs.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}