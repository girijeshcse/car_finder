{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girijeshcse/car_finder/blob/ambika/notebooks/cars_finder_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4gfufqRIn6l"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aShGdpJw8oN2"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNhSv_bQIyKb"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os \n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "  \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSZF8mm-Lm-A"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1QLZwXDRWEu"
      },
      "outputs": [],
      "source": [
        "ls \"/content/drive/MyDrive/Dataset/Car Images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEsktmWvurhk"
      },
      "outputs": [],
      "source": [
        "dataset_loc=\"/content/drive/MyDrive/\"\n",
        "train_annotation = pd.read_csv(dataset_loc+\"/Dataset/Annotations/Train Annotations.csv\")\n",
        "train_annotation.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvjONDEGvoXb"
      },
      "outputs": [],
      "source": [
        "entry = train_annotation.loc[train_annotation['Image Name'] == '02256.jpg'].values[0]\n",
        "#dim_analysis.loc[dim_analysis['dim3'] !=3 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQb7vuMpN6TW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhaF46ygGloi"
      },
      "outputs": [],
      "source": [
        "entry[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9mk4c0lELIm"
      },
      "outputs": [],
      "source": [
        "train_annotation.rename(columns = {'Bounding Box coordinates':'x0', 'Unnamed: 2':'yo', 'Unnamed: 3':'x1', 'Unnamed: 4':'y1'}, inplace = True)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekpY-iq7AEaC"
      },
      "outputs": [],
      "source": [
        "train_annotation.loc[train_annotation['Image Name'] == '00134.jpg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niHSCNGPFF8N"
      },
      "outputs": [],
      "source": [
        "train_annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOXopPrJPBNh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_images = pd.DataFrame(columns=['image','image_matrix','filename','car', 'x0', 'y0', 'x1', 'y1', 'label'])\n",
        "dim_analysis = pd.DataFrame(columns=['filename', 'dim1', 'dim2', 'dim3'])\n",
        "\n",
        "\n",
        "base=dataset_loc+\"/Dataset/Car Images/Train Images\"\n",
        "newsize = (128, 128)\n",
        "reshape_size = 128*128*3\n",
        "size_dim=128\n",
        "\n",
        "\n",
        "index = 0\n",
        "for dirs in os.listdir(base):\n",
        "    full_dir=base+\"/\"+dirs\n",
        "    \n",
        "    if os.path.isfile(full_dir):\n",
        "      continue\n",
        "    for file in os.listdir(os.path.join(full_dir)):\n",
        "      \n",
        "      if os.path.isfile(os.path.join(full_dir, file)):\n",
        "        filename=full_dir+\"/\"+file\n",
        "        im = Image.open(filename, mode='r')\n",
        "        dim_path=dirs+\"/\"+filename\n",
        "        image_width = im.size[1]\n",
        "        image_height = im.size[0]\n",
        "        dim_analysis = dim_analysis.append({'filename': filename, 'dim1':image_height, 'dim2':image_width}, ignore_index = True)\n",
        "  \n",
        "            #print(im.size[0])\n",
        "        im = im.resize(newsize)\n",
        "        pix_val = np.array(list(im.getdata()))\n",
        "        #print(\"\\t \\t\", len(pix_val.shape))\n",
        "        if ((len(pix_val.shape) >= 2) and (pix_val.shape[0]*pix_val.shape[1] == reshape_size)):\n",
        "          bound_box = train_annotation.loc[train_annotation['Image Name'] == file].values[0]\n",
        "          x0=bound_box[1]\n",
        "          x0 = int((x0 / image_width) * size_dim) \n",
        "\n",
        "          y0=bound_box[2]\n",
        "          y0 = int((y0 / image_height ) * size_dim)\n",
        "\n",
        "          x1=bound_box[3]\n",
        "          x1 = int((x1 / image_width)  * size_dim)\n",
        "\n",
        "          y1=bound_box[4]\n",
        "          y1 = int((y1 / image_height) * size_dim)\n",
        "          train_images = train_images.append({'image': pix_val.reshape(reshape_size), 'image_matrix': pix_val, 'filename':full_dir+\"/\"+file, 'car':dirs, 'x0': x0, 'y0':y0, 'x1':x1, 'y1':y1, 'label':bound_box[5]}, ignore_index = True)\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuidJimB97QC"
      },
      "outputs": [],
      "source": [
        "train_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oQZJ5MA-Ag_"
      },
      "outputs": [],
      "source": [
        "dim_analysis.loc[0, 'filename']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_HZ290UNqwh"
      },
      "outputs": [],
      "source": [
        "print(\"Various different dimensions of the image: \\n \", np.unique(dim_analysis['dim1']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAdQVLcXP0_r"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "print(\"Dimension Analysis:\\n\")\n",
        "val_count = dim_analysis['dim1'].value_counts()\n",
        "print(val_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shhP4ecnP_Yn"
      },
      "outputs": [],
      "source": [
        "\n",
        "sns.histplot(dim_analysis['dim1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiQttipfZkPI"
      },
      "outputs": [],
      "source": [
        "val_dict = dict(zip(train_images.car, train_images.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MnA1vrpahwf"
      },
      "outputs": [],
      "source": [
        "val_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6il8GJ1azdQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"car counts:\\n\")\n",
        "val_count = train_images['car'].value_counts()\n",
        "print(val_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlRq7sMtdKGh"
      },
      "outputs": [],
      "source": [
        "sns.histplot(train_images['car'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJyvC5jGN6Hx"
      },
      "outputs": [],
      "source": [
        "plt.imshow(im)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub6487U-Q_0G"
      },
      "outputs": [],
      "source": [
        "# few statistical analysis\n",
        "train_images.loc[train_images['car'] == 'GMC Savana Van 2012']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP2fP2T1hIAM"
      },
      "outputs": [],
      "source": [
        "len_train = train_images.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3AGqBE1ZvHF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Some random images\n",
        "for i in range( 2, 1000, 100):\n",
        "    print(\"=============\\n\", train_images.loc[i,'car'])\n",
        "    plt.imshow(train_images.loc[i, 'image'].reshape(size_dim, size_dim, 3))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkya7kq6kUyO"
      },
      "outputs": [],
      "source": [
        "dim_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUCSGS9ouhBZ"
      },
      "outputs": [],
      "source": [
        "def normalising_box(ind):\n",
        "  test_img = train_images.loc[ind, 'filename']\n",
        "  test_dim = dim_analysis.loc[dim_analysis['filename'] == test_img].values[0]\n",
        "  image_width = test_dim[2]\n",
        "  image_height = test_dim[1]\n",
        " \n",
        "  IMAGE_SIZE=128\n",
        "  x0=y_train[ind][0]\n",
        "  y0=y_train[ind][1]\n",
        "\n",
        "  x1=y_train[ind][2]\n",
        "  y1=y_train[ind][3]\n",
        "\n",
        "  print(x0, y0, x1, y1)\n",
        "  \n",
        "  x0 = int((x0 / image_width) * IMAGE_SIZE) # Scale the BBox\n",
        "  y0 = int((y0 / image_height ) * IMAGE_SIZE)\n",
        "\n",
        "  x1 = int((x1 / image_width)  * IMAGE_SIZE)\n",
        "  y1 = int((y1 / image_height) * IMAGE_SIZE)\n",
        "  print(x0, y0, x1, y1)\n",
        "  #return x0, y0, x1, y1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0C9B6NyE4BT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Extract the (flattened) data and class\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "#x_train = train_images['image_matrix']\n",
        "\n",
        "x_train = np.zeros((len_train, size_dim, size_dim, 3))\n",
        "y_train = np.zeros((len_train, 4))\n",
        "y_train_class = train_images['label']\n",
        "#y_train = train_images[5:7]\n",
        "for i in range(len(train_images)) :\n",
        "  x_train[i] = preprocess_input(np.array(train_images.loc[i,'image_matrix'].reshape(size_dim, size_dim, 3), dtype=np.float32))\n",
        "  y_train[i] = train_images.loc[i, 'x0':'y1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvgi8P0lki9v"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def patch_fn (ind):\n",
        "  \n",
        "  \n",
        "  # Create figure and axes\n",
        "  fig,ax = plt.subplots(1)\n",
        "  x0=y_train[ind][0]\n",
        "  y0=y_train[ind][1]\n",
        "\n",
        "  x1=y_train[ind][2]\n",
        "  y1=y_train[ind][3]\n",
        "  print(\"Normalised Bounding box: \", x0, y0, x1, y1)\n",
        "  # Display the image\n",
        "  ax.imshow(train_images.loc[ind,'image_matrix'].reshape(size_dim,size_dim,3))\n",
        "\n",
        "  # Create a Rectangle patch\n",
        "  rect = patches.Rectangle((x0, y0), x1 , y1, linewidth=2, edgecolor='r', facecolor='none')\n",
        "\n",
        "  # Add the patch to the Axes\n",
        "  ax.add_patch(rect)\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Niw9OVHukQYX"
      },
      "outputs": [],
      "source": [
        "#Some random bounding box examples\n",
        "patch_fn(50)\n",
        "#normalising_box(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "165XivnFr9RI"
      },
      "outputs": [],
      "source": [
        "patch_fn(200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKCl7YhhrsdM"
      },
      "outputs": [],
      "source": [
        "patch_fn(4000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmSp82zIHlCu"
      },
      "outputs": [],
      "source": [
        "patch_fn(6123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbP_QdG4mqbS"
      },
      "outputs": [],
      "source": [
        "x_train.shape, y_train.shape, y_train_class.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n113iG9qmtzw"
      },
      "outputs": [],
      "source": [
        "x_train[25], y_train[25], y_train_class[25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjPlq1z-wCMn"
      },
      "outputs": [],
      "source": [
        "del train_images, dim_analysis, train_annotation\n",
        "#gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFG7RaCmu2kD"
      },
      "source": [
        "Considering VGG16 to do object detection region and if needed SVM on the flatten layer to detect the class(196 class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs99mPYqaAzw"
      },
      "outputs": [],
      "source": [
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giDFz79NpHt2"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3tAAs0YwMuD"
      },
      "outputs": [],
      "source": [
        "dataset_loc=\"/content/drive/MyDrive/\"\n",
        "test_annotation = pd.read_csv(dataset_loc+\"/Dataset/Annotations/Test Annotation.csv\")\n",
        "test_annotation.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0EAQWRtffoY"
      },
      "outputs": [],
      "source": [
        "test_annotation.rename(columns = {'Bounding Box coordinates':'x0', 'Unnamed: 2':'yo', 'Unnamed: 3':'x1', 'Unnamed: 4':'y1'}, inplace = True)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNmGYMQ8YxUb"
      },
      "outputs": [],
      "source": [
        "#TEst images\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_images = pd.DataFrame(columns=['image','image_matrix','filename','car', 'x0', 'y0', 'x1', 'y1', 'label'])\n",
        "dim_analysis_test = pd.DataFrame(columns=['filename', 'dim1', 'dim2', 'dim3'])\n",
        "\n",
        "\n",
        "base=dataset_loc+\"/Dataset/Car Images/Test Images\"\n",
        "newsize = (128, 128)\n",
        "reshape_size = 128*128*3\n",
        "size_dim=128\n",
        "\n",
        "\n",
        "index = 0\n",
        "for dirs in os.listdir(base):\n",
        "    full_dir=base+\"/\"+dirs\n",
        "    \n",
        "    if os.path.isfile(full_dir):\n",
        "      continue\n",
        "    for file in os.listdir(os.path.join(full_dir)):\n",
        "      \n",
        "      if os.path.isfile(os.path.join(full_dir, file)):\n",
        "        filename=full_dir+\"/\"+file\n",
        "        im = Image.open(filename, mode='r')\n",
        "        dim_path=dirs+\"/\"+filename\n",
        "        image_width = im.size[1]\n",
        "        image_height = im.size[0]\n",
        "        dim_analysis_test = dim_analysis_test.append({'filename': filename, 'dim1':image_height, 'dim2':image_width}, ignore_index = True)\n",
        "\n",
        "        im = im.resize(newsize)\n",
        "        pix_val = np.array(list(im.getdata()))\n",
        "        if ((len(pix_val.shape) >= 2) and (pix_val.shape[0]*pix_val.shape[1] == reshape_size)):\n",
        "          bound_box = test_annotation.loc[test_annotation['Image Name'] == file].values[0]\n",
        "          x0=bound_box[1]\n",
        "          x0 = int((x0 / image_width) * size_dim) \n",
        "\n",
        "          y0=bound_box[2]\n",
        "          y0 = int((y0 / image_height ) * size_dim)\n",
        "\n",
        "          x1=bound_box[3]\n",
        "          x1 = int((x1 / image_width)  * size_dim)\n",
        "\n",
        "          y1=bound_box[4]\n",
        "          y1 = int((y1 / image_height) * size_dim)\n",
        "          test_images = test_images.append({'image': pix_val.reshape(reshape_size), 'image_matrix': pix_val, 'filename':full_dir+\"/\"+file, 'car':dirs, 'x0': x0, 'y0':y0, 'x1':x1, 'y1':y1, 'label':bound_box[5]}, ignore_index = True)\n",
        "          \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLYXgHp1ZIw8"
      },
      "outputs": [],
      "source": [
        "test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnvVfO0XZTtU"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "print(\"Dimension Analysis:\\n\")\n",
        "val_count = dim_analysis_test['dim1'].value_counts()\n",
        "print(val_count)\n",
        "\n",
        "sns.histplot(dim_analysis_test['dim1'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoaCeFeCZZEi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Some random images\n",
        "for i in range( 2, 1000, 100):\n",
        "    print(\"=============\\n\", test_images.loc[i,'car'])\n",
        "    plt.imshow(test_images.loc[i, 'image'].reshape(size_dim, size_dim, 3))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCq63xdhZumQ"
      },
      "outputs": [],
      "source": [
        "len_test = test_images.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRxO2SKdZmO0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Extract the (flattened) data and class\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "\n",
        "\n",
        "x_test = np.zeros((len_test, size_dim, size_dim, 3))\n",
        "y_test = np.zeros((len_test, 4))\n",
        "y_test_class = test_images['label']\n",
        "#y_train = train_images[5:7]\n",
        "for i in range(len(test_images)) :\n",
        "  x_test[i] = preprocess_input(np.array(test_images.loc[i,'image_matrix'].reshape(size_dim, size_dim, 3), dtype=np.float32))\n",
        "  y_test[i] = test_images.loc[i, 'x0':'y1']\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_class"
      ],
      "metadata": {
        "id": "-FPYh54qKCHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2s9s2jxjJ59"
      },
      "outputs": [],
      "source": [
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUNkUzrWZ-V-"
      },
      "outputs": [],
      "source": [
        "x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns8fxVD0jJQT"
      },
      "outputs": [],
      "source": [
        "del test_images, dim_analysis_test, test_annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwCqVVo2TIlT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import Xception # TensorFlow ONLY\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "IMAGE_SIZE=128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxbLlxvbmeFM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, Reshape\n",
        "\n",
        "ALPHA = 1.0 # Width hyper parameter for MobileNet (0.25, 0.5, 0.75, 1.0). Higher width means more accurate but slower\n",
        "\n",
        "\n",
        "model = MobileNet(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA) # Load pre-trained mobilenet\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn2WmVq-nYcI"
      },
      "outputs": [],
      "source": [
        "# Add new top layer which is a conv layer of the same size as the previous layer so that only 4 coords of BBox can be output\n",
        "x0 = model.layers[-1].output\n",
        "x1 = Conv2D(4, kernel_size=4, name=\"coords\")(x0)\n",
        "x2 = Reshape((4,))(x1)\n",
        "model_region = Model(inputs=model.input, outputs=x2)\n",
        "model_region.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar16VQ6QF-RH"
      },
      "outputs": [],
      "source": [
        "model_region.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r69xSusOey75"
      },
      "outputs": [],
      "source": [
        "def IOU(y_true, y_pred):\n",
        "    intersections = 0\n",
        "    unions = 0\n",
        "    # set the types so we are sure what type we are using\n",
        "\n",
        "    gt = y_true\n",
        "    pred = y_pred\n",
        "    # Compute interection of predicted (pred) and ground truth (gt) bounding boxes\n",
        "    diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n",
        "    diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n",
        "    intersection = diff_width * diff_height\n",
        "\n",
        "    # Compute union\n",
        "    area_gt = gt[:,2] * gt[:,3]\n",
        "    area_pred = pred[:,2] * pred[:,3]\n",
        "    union = area_gt + area_pred - intersection\n",
        "\n",
        "    # Compute intersection and union over multiple boxes\n",
        "    for j, _ in enumerate(union):\n",
        "      if union[j] > 0 and intersection[j] > 0 and union[j] >= intersection[j]:\n",
        "        intersections += intersection[j]\n",
        "        unions += union[j]\n",
        "\n",
        "    # Compute IOU. Use epsilon to prevent division by zero\n",
        "    iou = np.round(intersections / (unions + tensorflow.keras.backend.epsilon()), 4)\n",
        "    # This must match the type used in py_func\n",
        "    iou = iou.astype(np.float32)\n",
        "    return iou\n",
        "\n",
        "def IoU(y_true, y_pred):\n",
        "    iou = tensorflow.py_function(IOU, [y_true, y_pred], Tout=tensorflow.float32)\n",
        "    return iou\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHVYoLLWecE_"
      },
      "outputs": [],
      "source": [
        "model_region.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[IoU]) # Regression loss is MSE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_A0II4UeRGY"
      },
      "outputs": [],
      "source": [
        "callback = tensorflow.keras.callbacks.EarlyStopping(monitor='IoU', patience=10, min_delta=0.001)\n",
        "\n",
        "# Fit the model\n",
        "model_region.fit(x_train, y_train,validation_data =(x_test, y_test), epochs=200, batch_size=32, callbacks=[callback])\n",
        "#, callbacks=[callback])\n",
        "#, validation_data=(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWl-xa9DnYh0"
      },
      "outputs": [],
      "source": [
        "model_region.evaluate(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_region.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "xZ5XZJ0NFW2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1KWLYz9n5GC"
      },
      "outputs": [],
      "source": [
        "x_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nKD3-NNnsK3"
      },
      "outputs": [],
      "source": [
        "model_region.predict(x_train[0].reshape(1, 128, 128, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4uHCEJ4oAGq"
      },
      "outputs": [],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_class=to_categorical(y_train_class)\n",
        "\n",
        "y_test_class=to_categorical(y_test_class)"
      ],
      "metadata": {
        "id": "YidPbhJCHlHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_class[250]"
      ],
      "metadata": {
        "id": "asjuTLPeJcGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_class.shape, y_test_class.shape"
      ],
      "metadata": {
        "id": "YfIsqlGXCIpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qr7m3D6kV5X"
      },
      "outputs": [],
      "source": [
        "base_model_resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(128,128,3),classes=y_test_class.shape[1])\n",
        "base_model_vgg16 = VGG16(include_top=False,weights='imagenet',input_shape=(128,128,3),classes=y_test_class.shape[1])\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dropout, BatchNormalization, Dense\n",
        "for layer in base_model_vgg16.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "#Defining and Adding layers\n",
        "model_class=Sequential()\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_class.add(base_model_vgg16)\n",
        "model_class.add(Flatten())\n",
        "\n",
        "model_class.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_class.add(Dense(2048,activation=('relu'),input_dim=8192))\n",
        "model_class.add(Dense(1024,activation=('relu'))) \n",
        "model_class.add(Dropout(.4))\n",
        "model_class.add(Dense(512,activation=('relu'))) \n",
        "model_class.add(Dropout(.3))#Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_class.add(Dense(256,activation=('relu')))\n",
        "model_class.add(Dropout(.2))\n",
        "model_class.add(Dense(197,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "#Model summary"
      ],
      "metadata": {
        "id": "SLtHNQ7DGFxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.summary()"
      ],
      "metadata": {
        "id": "ekwxPDd5G8TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "vXYl-A3kmGoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the parameters\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "batch_size= 100\n",
        "epochs=30\n",
        "learn_rate=.01\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.01,nesterov=False)\n",
        "\n",
        "\n",
        "opt = RMSprop(learning_rate=1)\n",
        "#Compile\n",
        "model_class.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#Training\n",
        "#model_class.fit(x_train, y_train_class,validation_data =(x_test, y_test_class), epochs=100, batch_size=32)\n",
        "#model_class.fit(x_test, y_test_class, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "0Bji9bR7JDSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.fit(x_train, y_train_class,validation_data =(x_test, y_test_class), epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "kEwUSMsWhpEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.fit(x_train, y_train_class,validation_data =(x_test, y_test_class), epochs=200, batch_size=32)"
      ],
      "metadata": {
        "id": "2CX2h-1QnYk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.fit(x_train, y_train_class,validation_data =(x_test, y_test_class), epochs=200, batch_size=32)"
      ],
      "metadata": {
        "id": "n8oriLzu5A5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.evaluate(x_train, y_train_class)"
      ],
      "metadata": {
        "id": "h8cI_ALb5l1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.evaluate(x_test, y_test_class)"
      ],
      "metadata": {
        "id": "VQ5VWdWF5lqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_class.predict(x_train[10].reshape(1, 128, 128, 3))"
      ],
      "metadata": {
        "id": "5bfol-5c5lfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_class[10]"
      ],
      "metadata": {
        "id": "iTUOhctd50El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow.keras.backend.clear_session()\n",
        "#del model_class\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "PmL3sEiWqP-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "cars finder .ipynb",
      "provenance": [],
      "mount_file_id": "1rgoMxsaMaFErZG5evoTpGJ0dC-Fz1OZq",
      "authorship_tag": "ABX9TyOs1V26niJiH4FLw1us4RlI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}